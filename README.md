# ComfyUI-Qwen3-llama.cpp
Custom nodes for ComfyUI QWen3 8b running based on llama.cpp, which only support the CUDA framework and do not support MPS.

## Installation
Download or git clone this repository into the ComfyUI\custom_nodes\ directory and run:

```bash
pip install -r requirements.txt
```
